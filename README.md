# üëã Hi, I‚Äôm @abdeladime2003

## About Me
- üëÄ I‚Äôm interested in **data science** and **data engineering**.
- üå± I‚Äôm currently learning data engineering, focusing on:
  - Programming languages: Python, SQL
  - Big data technologies: Hadoop, Spark
  - Data warehousing: Amazon Redshift, Google BigQuery
  - Data visualization: Tableau, Power BI
- üíº I‚Äôm passionate about turning data into actionable insights and building efficient data pipelines.
- üíûÔ∏è I‚Äôm looking to collaborate on projects involving:
  - Data analysis and visualization
  - Building and optimizing data pipelines
  - Implementing machine learning models
- üì´ How to reach me:
  - Email: [abdeladimebenali2003@gmail.com](mailto:abdeladimebenali2003@gmail.com)
  - LinkedIn: [linkedin.com/in/abdeladime2003]([https://linkedin.com/in/abdeladime200](https://www.linkedin.com/in/abdeladime-benali-83579a284/?lipi=urn%3Ali%3Apage%3Ad_flagship3_feed%3BTJBgDVU0SAerc20e1S4Djg%3D%3D)3)
- üòÑ Pronouns: He/Him
- ‚ö° Fun fact: I enjoy solving complex data problems, playing chess, and exploring new data technologies in my free time.

## Skills
- **Programming Languages:** Python, SQL
- **Data Warehousing:** Amazon Redshift, Google BigQuery
- **Data Visualization:** Tableau, Power BI
- **Machine Learning:** Scikit-learn, TensorFlow

## Projects

### Uniting Web Scraping, Data Analysis, ML Modeling, and Streamlit Visualization
Our project integrates key processes essential for data scientists:
1. **Data Acquisition:** Web scraping of Transfermarkt and FIFA Stats websites.
2. **Data Manipulation and Preprocessing:** Constructing a predictive model using techniques like linear regression.
3. **Model Deployment:** Using Streamlit to develop an application allowing interactive feature adjustments and player fee predictions.

**Project Structure:**
- **python_project:** Contains the main Python code.
  - **step1:** Initial steps, including data preprocessing and web scraping notebooks.
  - **step2:** Intermediate steps with model training.
  - **step3:** Final steps with data preprocessing class, video demonstration, and website interface.

**Directories:**
- `data`: Contains CSV files with datasets.
- `virtuel_environement`: Virtual environment setup files.

**Usage:**
1. Clone the repository: `git clone https://github.com/votre-nom-utilisateur/projet_baina.git`
2. Install virtual environment: `python -m venv venv`
3. Activate virtual environment: `venv\Scripts\activate`
4. Install dependencies: `pip install -r requirements.txt`
5. Navigate and execute scripts or notebooks within the `python_project` directory.

**Dependencies:** Ensure required dependencies from `virtuel_environement/requirements.txt` are installed.

**Project Demonstration:** [Google Drive Link](https://drive.google.com)

### Gestionnaire de Football
A Java and JavaFX application to manage football-related entities such as teams, transfers, and competitions.

**Main Features:**
1. **Team Management:** Add, modify, and delete teams; view team details.
2. **Transfer Management:** Track player transfers, including details like amounts and dates.
3. **Competition Management:** Create, schedule, and manage football competitions; view match results and team statistics.
4. **User-Friendly Interface:** Four graphical windows (CompetitionWindow, EquipeWindow, TransfertWindow, LoginWindow) and a main coordination window.

**Technologies Used:**
- **Programming Language:** Java
- **Graphical Library:** JavaFX

### Portfolio
Personal portfolio showcasing skills, projects, and contact information.

**Project Structure:**
- **Html_file:** Contains HTML files for each page (Contact-Me.html, My_profile.html, etc.).
- **Css_File:** Contains CSS files for styling each page (Acceuil.css, Contact-Me.css, etc.).
- **Icon and images:** Contains images and icons used in the pages.
- **Main_File:** Main HTML file to start the portfolio.
- **Demo.txt:** Link to video demonstration on Google Drive.

**Usage:** Open the main HTML file in any HTML5-compatible web browser.

### Stock Market Prediction with LightGBM
Developing a robust machine learning model using LightGBM for predicting stock prices based on historical data.

**Key Features:**
- Utilizes LightGBM for regression tasks.
- Implements advanced data preprocessing techniques.
- Generates key indicators like spread, mid-price, and RSI for feature engineering.
- Visualizes correlations and feature importances.

**Getting Started:**
1. Clone the repository: `git clone https://github.com/abdeladime2003/Optiver-Trading-at-the-close.git`
2. Install dependencies: `pip install -r requirements.txt`
3. Explore the Jupyter notebooks in the `Stormy` directory.

**Files Structure:**
- **data:** Contains the link to download the data.
- **Stormy:** Includes Jupyter notebooks for data preprocessing, model training, and evaluation.

**License:** This project is licensed under the MIT License.

**Acknowledgments:** Thanks to the open-source community and the developers of LightGBM.

<!---
abdeladime2003/abdeladime2003 is a ‚ú® special ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
